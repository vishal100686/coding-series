import tensorflow as tf
import numpy as np

# Load Data
(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()
X_train = X_train / 255.0  # Normalize
X_train = np.expand_dims(X_train, axis=-1)  # Shape (28,28,1)

# Build Generator
def build_generator():
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(128, activation='relu', input_shape=(100,)),
        tf.keras.layers.Dense(28 * 28 * 1, activation='sigmoid'),
        tf.keras.layers.Reshape((28, 28, 1))
    ])
    return model

# Build Discriminator
def build_discriminator():
    model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    return model

# Compile GAN
generator = build_generator()
discriminator = build_discriminator()
discriminator.compile(optimizer='adam', loss='binary_crossentropy')

gan = tf.keras.Sequential([generator, discriminator])
gan.compile(optimizer='adam', loss='binary_crossentropy')

# Training GAN
for epoch in range(10000):
    noise = np.random.randn(32, 100)  # Random noise
    fake_images = generator.predict(noise, verbose=0)
    real_images = X_train[np.random.randint(0, X_train.shape[0], 32)]
    X = np.concatenate([fake_images, real_images])
    y = np.concatenate([np.zeros(32), np.ones(32)])

    discriminator.train_on_batch(X, y)
    gan.train_on_batch(noise, np.ones(32))

print("GAN Training Complete!")
